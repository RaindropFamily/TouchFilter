


CUDA_VISIBLE_DEVICES=0 python train.py --batch_size 24 --lr_des 1e-5 --lr_gen 1e-4 --langevin_random_size 0.1 --step_size 0.1 --langevin_steps 30 --latent_factor_merge concat --name exp0 2> logs/STDERR-0
CUDA_VISIBLE_DEVICES=6 python train.py --batch_size 24 --lr_des 1e-5 --lr_gen 1e-5 --langevin_random_size 0.1 --step_size 0.1 --langevin_steps 30 --latent_factor_merge concat --name exp1 2> logs/STDERR-1
- CUDA_VISIBLE_DEVICES=2 python train.py --batch_size 24 --lr_des 1e-5 --lr_gen 1e-4 --langevin_random_size 0.1 --step_size 0.1 --langevin_steps 30 --latent_factor_merge add --name exp2 2> logs/STDERR-2
- CUDA_VISIBLE_DEVICES=3 python train.py --batch_size 24 --lr_des 1e-5 --lr_gen 1e-5 --langevin_random_size 0.1 --step_size 0.1 --langevin_steps 30 --latent_factor_merge add --name exp3 2> logs/STDERR-3
CUDA_VISIBLE_DEVICES=4 python train.py --batch_size 24 --lr_des 1e-5 --lr_gen 1e-4 --langevin_random_size 0.1 --step_size 0.1 --langevin_steps 90 --latent_factor_merge concat --name exp4 2> logs/STDERR-4
CUDA_VISIBLE_DEVICES=5 python train.py --batch_size 24 --lr_des 1e-5 --lr_gen 1e-5 --langevin_random_size 0.1 --step_size 0.1 --langevin_steps 90 --latent_factor_merge concat --name exp5 2> logs/STDERR-5
- CUDA_VISIBLE_DEVICES=6 python train.py --batch_size 24 --lr_des 1e-5 --lr_gen 1e-4 --langevin_random_size 0.1 --step_size 0.1 --langevin_steps 90 --latent_factor_merge add --name exp6 2> logs/STDERR-6
CUDA_VISIBLE_DEVICES=7 python train.py --batch_size 24 --lr_des 1e-5 --lr_gen 1e-5 --langevin_random_size 0.1 --step_size 0.1 --langevin_steps 90 --latent_factor_merge add --name exp7 2> logs/STDERR-7


2020-05-18 experiment plan:
2. run exp with new setup
  2.1. use static z2 instead of dynamic z2  [check]
  2.2. generator also takes obj pointcloud as input
  2.3. use all object and include rotation  [check]

CUDA_VISIBLE_DEVICES=0 python train.py --batch_size 32 --lr_des 1e-5 --lr_gen 1e-3 --langevin_random_size 0.1 --step_size 0.1 --langevin_steps 10 --latent_factor_merge concat --name exp0 2> logs/STDERR-0
CUDA_VISIBLE_DEVICES=4 python train.py --batch_size 32 --lr_des 1e-5 --lr_gen 1e-3 --langevin_random_size 0.1 --step_size 0.1 --langevin_steps 30 --latent_factor_merge concat --name exp1 2> logs/STDERR-1
CUDA_VISIBLE_DEVICES=5 python train.py --batch_size 32 --lr_des 1e-5 --lr_gen 1e-3 --langevin_random_size 0.1 --step_size 0.1 --langevin_steps 90 --latent_factor_merge concat --name exp2 2> logs/STDERR-2
CUDA_VISIBLE_DEVICES=6 python train.py --batch_size 32 --lr_des 1e-5 --lr_gen 1e-3 --langevin_random_size 0.1 --step_size 0.1 --langevin_steps 10 --latent_factor_merge add --name exp3 2> logs/STDERR-3
CUDA_VISIBLE_DEVICES=7 python train.py --batch_size 32 --lr_des 1e-5 --lr_gen 1e-3 --langevin_random_size 0.1 --step_size 0.1 --langevin_steps 30 --latent_factor_merge add --name exp4 2> logs/STDERR-4


CUDA_VISIBLE_DEVICES=0 python train.py --batch_size 32 --lr_des 1e-5 --lr_gen 1e-3 --langevin_random_size 0.1 --step_size 0.1 --langevin_steps 30 --weight_decay 0.01 --latent_factor_merge concat --name exp0 2> logs/STDERR-0
CUDA_VISIBLE_DEVICES=4 python train.py --batch_size 32 --lr_des 1e-5 --lr_gen 1e-3 --langevin_random_size 0.1 --step_size 0.1 --langevin_steps 30 --weight_decay 0.1 --latent_factor_merge concat --name exp1 2> logs/STDERR-1
CUDA_VISIBLE_DEVICES=5 python train.py --batch_size 32 --lr_des 1e-5 --lr_gen 1e-3 --langevin_random_size 0.1 --step_size 0.1 --langevin_steps 30 --weight_decay 1 --latent_factor_merge concat --name exp2 2> logs/STDERR-2
CUDA_VISIBLE_DEVICES=6 python train.py --batch_size 32 --lr_des 1e-5 --lr_gen 1e-3 --langevin_random_size 0.1 --step_size 0.1 --langevin_steps 30 --weight_decay 0.01 --latent_factor_merge add --name exp3 2> logs/STDERR-3
CUDA_VISIBLE_DEVICES=7 python train.py --batch_size 32 --lr_des 1e-5 --lr_gen 1e-3 --langevin_random_size 0.1 --step_size 0.1 --langevin_steps 30 --weight_decay 0.1 --latent_factor_merge add --name exp4 2> logs/STDERR-4



CUDA_VISIBLE_DEVICES=4 python train.py --batch_size 28 --lr_des 1e-5 --lr_gen 1e-4 --langevin_random_size 0.1 --step_size 0.1 --langevin_steps 30 --weight_decay 2 --latent_factor_merge concat --name exp0 2> logs/STDERR-0
CUDA_VISIBLE_DEVICES=5 python train.py --batch_size 28 --lr_des 1e-5 --lr_gen 1e-4 --langevin_random_size 0.1 --step_size 0.1 --langevin_steps 30 --weight_decay 4 --latent_factor_merge concat --name exp1 2> logs/STDERR-1
CUDA_VISIBLE_DEVICES=6 python train.py --batch_size 28 --lr_des 1e-5 --lr_gen 1e-4 --langevin_random_size 0.1 --step_size 0.1 --langevin_steps 30 --weight_decay 6 --latent_factor_merge concat --name exp2 2> logs/STDERR-2
CUDA_VISIBLE_DEVICES=7 python train.py --batch_size 28 --lr_des 1e-5 --lr_gen 1e-4 --langevin_random_size 0.1 --step_size 0.1 --langevin_steps 30 --weight_decay 8 --latent_factor_merge concat --name exp3 2> logs/STDERR-3

2020-06-07 observation
* For the first few epochs, step_size=10 x langevin_steps=45 is the only one that produces synthesis result with energy lower than gt after epoch 0.
* This does not happen with step_size=1 x langevin_steps=450. This means that the larger step langevin dynamics goes out of scope of the learned energy landscape.
* Meaning the learned energy landscape is too spikey. Probably because there is too many parameters than necessary. 
* FIX: run experiment with a smaller pointnet network. 
* FIX: train with only syn energies lower than mean obs energy. This would hopefully reduce the energy explosion problem

python train.py --batch_size 28 --lr_des 1e-4 --lr_gen 1e-4 --langevin_random_size 0.01 --step_size 0.1 --langevin_steps 30 
        --weight_decay 0 --latent_factor_merge concat --name exp0 2> logs/STDERR-0